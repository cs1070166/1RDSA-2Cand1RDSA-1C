\section{CONVERGENCE ANALYSIS}
\label{sec:convergenceresults}
We make the same assumptions as those used in the analysis of \cite{spall}, with a 
few minor alterations. The assumptions are listed below. Also $\|.\|$ denotes 2-norm.
\begin{enumerate}[label= \textbf{(A\arabic*)}]
 \item The map $J:\mathbb{R}^p \rightarrow \mathbb{R}$ is Lipschitz continuous and 
 is differentiable with bounded second order derivatives. Further, 
 the map $L:\mathbb{R}^p \rightarrow \mathbb{R}$ defined as 
 $L(\theta)=-\nabla J(\theta)$ is Lipschitz continuous.
 \item The step-size sequences $a_n, \delta_n >0, \forall n $  satisfy
 \begin{equation*}\label{stepsizes}
 a_n,\delta_n \rightarrow 0 , \sum_na_n=\infty,
 \sum_n \Big{(}\frac{a_n}{\delta_n}\Big{)}^2<\infty.
 \end{equation*}
 Further, $\frac{a_j}{a_n}\rightarrow 1$ as $n\rightarrow \infty$, for all
 $j \in \{n,n+1,n+2\cdots,n+M\}$ for any given $M>0$ and $b_n=\frac{a_n}{\delta_n}$ is 
 such that $\frac{b_j}{b_n}\rightarrow 1$ as $n\rightarrow \infty$, for all
 $j \in \{n,n+1,n+2,\cdots,n+M\}.$

<<<<<<< HEAD
 \item $\max_n \|d_n\|= C, \max_n \|D_n\|= \bar{C}$. 
%  The vectors $d_n$, $n\geq0$ are mutually independent and identically
%  distributed. Moreover $\mathbb{E}[d_nd_n^T]=I.$
=======
 \item The random vectors $d_n$, $n\geq0$ are mutually independent and identically
 distributed. Moreover $\mathbb{E}[d_nd_n^T]=I.$
>>>>>>> 93fae88bc6e797f3da4d04bebec0b8c716513539
 
 \item The iterates $\theta_n$ remain uniformly bounded almost surely, i.e.,
 $$ \sup_n\|\theta_n\|<\infty, a.s.$$

 \item The ODE $\dot{\theta}(t)=-\nabla J(\theta(t))$ has a compact set 
 $G \subset \mathbb{R}^p$ as its set of asymptotically stable equilibria
 (i.e., the set of local minima of $J$ is compact).
 
 
 \item The sequences $(M_{n}^{+},\F_n),(M_{n}^{-},\F_n), n\geq0 $ form martingale difference sequences.
 Further, $(M_{n}^{+},M_{n}^{-},n\geq0)$ are square integrable random variables satisfying
 $$\E[\|M_{n+1}^{\pm}\|^2|\F_n]\leq K(1+\|\theta_n\|^2) \text{ a.s., } \forall n\geq0,$$
 for a given constant $K \geq 0.$
 
\end{enumerate}
The following lemma is useful in obtaining the negative square root of $H$ i.e., 
$H^{-1/2}$. Also note that it takes only $O(p)$ operations to compute $H^{-1/2}$
using the lemma and circulant structure of $H^{-1/2}$.
\begin{lemma}
 \label{lemma: gen Sherman-Morisson}
Let $I$ be a $p \times p$ identity matrix and $u = 
\left[
 \begin{array}{cccc}
 1 \\ 1 \\  \vdots \\ 1 
\end{array} \right]$ be a $p \times 1$ vector of 1s, then
$$ (I+uu^T)^{-1/2}= I-\frac{uu^T}{p}+\frac{uu^T}{p\sqrt{(1+p)}}.$$
\end{lemma}
\begin{proof}
It is enough to show that
$$(I+uu^T)\Bigg{[}I-\frac{uu^T}{p}+\frac{uu^T}{p\sqrt{(1+p)}}\Bigg{]}^2=I.$$
% Using $\|u\|^2=u^Tu=p$ in the expansion of $\Bigg{[}I-\frac{uu^T}{p}+\frac{uu^T}{p\sqrt{(1+p)}}\Bigg{]}^2$
% gives the result.
Using $\|u\|^2=u^Tu=p$ we have
\begin{align*}
 & (I+uu^T)\Bigg{[}I-\frac{uu^T}{p}+\frac{uu^T}{p\sqrt{(1+p)}}\Bigg{]}^2\\
 &= (I+uu^T)\Bigg{[}I-\frac{uu^T}{p}+\frac{uu^T}{p\sqrt{(1+p)}}\\
 &-\frac{uu^T}{p}+\frac{uu^Tuu^T}{p^2}-\frac{uu^Tuu^T}{p^2\sqrt{(1+p)}}\\
 &+\frac{uu^T}{p\sqrt{(1+p)}}-\frac{uu^Tuu^T}{p^2\sqrt{(1+p)}}+\frac{uu^Tuu^T}{p^2(1+p)}\Bigg{]}\\
 &= (I+uu^T)\Bigg{[}I-\frac{uu^T}{p}+\frac{uu^T}{p\sqrt{(1+p)}}\\
 &-\frac{uu^T}{p}+\frac{uu^T}{p}-\frac{uu^T}{p\sqrt{(1+p)}}\\
 &+\frac{uu^T}{p\sqrt{(1+p)}}-\frac{uu^T}{p\sqrt{(1+p)}}+\frac{uu^T}{p(1+p)}\Bigg{]}\\
 &=(I+uu^T)\Bigg{[}I-uu^T(\frac{1}{p}-\frac{1}{p(1+p)})\Bigg{]}\\
 &=(I+uu^T)\Bigg{[}I-\frac{uu^T}{1+p}\Bigg{]}\\
 &=I+uu^T-\frac{uu^T}{1+p}-\frac{puu^T}{1+p}\\
 &=I
\end{align*}
proving the lemma.
\end{proof}
<<<<<<< HEAD
Let $H$ defined as in \eqref{eq:H} and $Q=\sqrt{p+1}[H^{-1/2},-H^{-1/2}u].$
Let the pertubations $d_n$ be the columns of Q. 
\begin{lemma}
 The perturbations $d_n$ chosen as columns of Q satisfy properties (P1) and (P2).
=======
As defined earlier let \begin{equation*} H = \left[\begin{array}{cccc}
2 \ 1 \ 1 \cdots 1\\ 
1 \ 2 \ 1 \cdots 1 \\
\vdots \ \vdots \ \vdots \ \vdots\\
1 \ 1 \ 1 \cdots 2
\end{array}\right]
\end{equation*}
and $Q=\sqrt{p+1}[H^{-1/2},-H^{-1/2}u].$
Let the perturbations $d_n$ be the columns of Q. 
\begin{lemma}
 The perturbations $d_n$ chosen as columns of Q satisfy properties P1 and P2.
>>>>>>> 93fae88bc6e797f3da4d04bebec0b8c716513539
\end{lemma}
\begin{proof}
 Let $P=p+1$. Observe that as $n$ goes through one cycle from $1$ to $p+1$ we have
 $\sum\limits_{n=1}^{p+1}d_nd_n^T=QQ^T$ and 
 $\sum\limits_{n=1}^{p+1}d_n= Q\left[\begin{array}{cccc}
 u\\ 1 \end{array}\right]$.
 Now it is enough to show that
 $\sum\limits_{n=s+1}^{s+P}D_n=0$ and 
 $\sum\limits_{n=s+1}^{s+P}d_n= 0$ i.e., 
 $Q\left[\begin{array}{cccc}
 u\\ 1 \end{array}\right]=0 \text{ for the choice } s=0.$
 Consider
 \begin{align*}
 & \sum_{n=0}^{P}D_n=\sum_{n=1}^{P}(d_nd_n^T-I)\\
 & =\sum_{n=1}^{P}(d_nd_n^T)-(p+1)I\\
 & =QQ^T-(p+1)I\\
 & =(p+1)([H^{-1/2},-H^{-1/2}u][H^{-1/2},-H^{-1/2}u]^T-I)\\
 & =(p+1)([H^{-1}+H^{-1/2}uu^TH^{-1/2}]-I)\\
 & =(p+1)(H^{-1/2}(I+uu^T)H^{-1/2}-I)\\
 & =(p+1)(H^{-1/2}(H)H^{-1/2}-I)\\
 & = 0.
 \end{align*}
 In addition,
 \begin{align*}
 Q\left[\begin{array}{cccc}
 u\\ 1 \end{array}\right]
 & = \sqrt{p+1}([H^{-1/2},-H^{-1/2}u]) \left[\begin{array}{cccc}
 u\\ 1 \end{array}\right]\\
 & = \sqrt{p+1}(H^{-1/2}u-H^{-1/2}u)\\
 & = 0
 \end{align*}
proving the lemma.
\end{proof}
\begin{lemma}
 Given any fixed integer $P>0$, $\|\theta_{m+k}-\theta_{m}\| \rightarrow 0$ $w.p.1,$ as
 $m \rightarrow \infty,$ for all $k \in \{1,\cdots, P\}$
\end{lemma}
\begin{proof}
 Fix a $k \in \{1,\cdots,P \}.$ Now
 \begin{align*}
 \begin{split}
 \theta_{n+k} = \theta_n & -\sum_{j=n}^{n+k-1}a_j\Bigg{(}\frac{J(\theta_j+\delta_j d_j)-J(\theta_j-\delta_j d_j)}{2\delta_j}\Bigg{)}d_j \\ 
  &-\sum_{j=n}^{n+k-1}a_jM_{j+1}.
 \end{split}
 \end{align*}
 Thus,
 \begin{align*}
 \begin{split}
 \|\theta_{n+k}-\theta_n\| &\leq \sum_{j=n}^{n+k-1}a_j\Bigg{|}\frac{J(\theta_j+\delta_{j} d_j)-J(\theta_j-\delta_{j} d_j)}{2\delta_j}\Bigg{|}\|d_j\|\\
 &+\sum_{j=n}^{n+k-1}a_j\|M_{j+1}\|
\end{split}
 \end{align*}
Now clearly,
$$N_n=\sum_{j=0}^{n-1}a_jM_{j+1}, n\geq1,$$
forms a martingale sequence with respect to the filtration $\{\F_n\}$.
Further, from the assumption (A6) we have,
\begin{align*}
\sum_{m=0}^{n}\mathbb{E}[\|N_{m+1}-N_{m}\|^2|\mathcal{F}_{m}]& =\sum_{m=0}^{n}\mathbb{E}[a_{m}^2\|M_{m+1}\|^2|\mathcal{F}_{m}]\\
& \leq \sum_{m=0}^{n}a_{m}^2K(1+\|\theta_m\|^2)
\end{align*}
From the assumption (A4), the quadratic variation process of $N_n,n\geq0$ converges 
almost surely. Hence by the martingale convergence theorem, it follows that 
$N_n, n\geq0$ converges almost surely. Hence
$\|\sum\limits_{j=n}^{n+k-1}a_jM_{j+1}\|\rightarrow 0$ almost surely as $n\rightarrow \infty.$
Moreover
\begin{align*}
&\Big{\|}\Big{(}J(\theta_j+\delta_j d_j)-J(\theta_j-\delta_j d_j)\Big{)}d_j\Big{\|} \\
& \leq \Big{|}\Big{(}J(\theta_j+\delta_j d_j)-J(\theta_j-\delta_j d_j)\Big{)}\Big{|}\|d_j\|\\
& \leq C \Big{(}|J(\theta_j+\delta_j d_j)|+|J(\theta_j-\delta_j d_j)|\Big{)},
\end{align*}
since $\|d_j\|\leq C, \forall j \geq0.$
Note that
\begin{align*}
|J(\theta_j+\delta_j d_j)|-|J(0)| & \leq|J(\theta_j+\delta_j d_j)-J(0)| \\
& \leq \hat{B} \|\theta_j+\delta_j d_j\|,
\end{align*}
where $\hat{B}$ is the Lipschitz constant of the function $J(.).$ Hence,
$$|J(\theta_j+\delta_j d_j)|\leq \tilde{B}(1+\|\theta_j+\delta_j d_j\|),$$
for $\tilde{B}=$max$(|J(0)|,\hat{B}).$ Similarly,
$$|J(\theta_j-\delta_j d_j)|\leq \tilde{B}(1+\|\theta_j-\delta_j d_j\|).$$
From assumption (A1), it follows that
$$\sup_j\Big{\|}\Big{(}J(\theta_j+\delta_j d_j)-J(\theta_j-\delta_j d_j)\Big{)}d_j\Big{\|}\leq \tilde{K}<\infty,$$
for some $\tilde{K}>0.$ Thus,
$$\|\theta_{n+k}-\theta_n\| \leq \tilde{K}\sum_{j=n}^{n+k-1}\frac{a_j}{\delta_j}+\|\sum_{j=n}^{n+k-1}a_jM_{j+1}\|$$
$$\rightarrow 0 \text{ a.s. with } n \rightarrow \infty$$
proving the lemma.
\end{proof}
\begin{lemma}
\begin{align*}
&\text{ For any } m \geq0,\\
&\Big{\|}\sum_{n=m}^{m+P-1}\frac{a_n}{a_m}D_n\nabla J(\theta_n)\Big{\|}\rightarrow 0 \text{ and }\\
&\Big{\|}\sum_{n=m}^{m+P-1}\frac{b_n}{b_m}d_nJ(\theta_n)\Big{\|}\rightarrow 0,
\text{almost surely, as } m \rightarrow \infty.
\end{align*}
\end{lemma}
\begin{proof}
 From lemma 3, it can be seen that
  $\|\theta_{m+s}-\theta_{m}\|\rightarrow 0$ as $m\rightarrow \infty,$
 for all $s=1,\cdots,P.$ Also from assumption (A1), we have
 $\|\nabla J(\theta_{m+s})-\nabla J(\theta_{m})\|\rightarrow 0$ as $m\rightarrow \infty,$
 for all $s=1,\cdots,P.$ Now from lemma 2, $\sum\limits_{n=m}^{m+P-1}D_n=0$ $\forall m\geq0.$
 Hence $D_m=-\sum\limits_{n=m+1}^{m+P-1}D_n.$ Thus we have, 
 \begin{align*}
  &\Big{\|}\sum_{n=m}^{m+P-1}\frac{a_n}{a_m}D_n\nabla J(\theta_n)\Big{\|}\\
  & = \Big{\|}\sum_{n=m+1}^{m+P-1}\frac{a_n}{a_m}D_n\nabla J(\theta_n)
  +D_{m}\nabla J(\theta_{m})\Big{\|}\\
  &=\Big{\|}\sum_{n=m+1}^{m+P-1}\frac{a_n}{a_m}D_n \nabla J(\theta_n)
     -\sum_{n=m+1}^{m+P-1}D_n\nabla J(\theta_{m})\Big{\|}\\
  &=\Big{\|}\sum_{n=m+1}^{m+P-1}D_n\Big{(}\frac{a_n}{a_m}\nabla J(\theta_n)
  -\nabla J(\theta_{m})\Big{)}\Big{\|}\\
  &\leq \bar{C}\sum_{n=m+1}^{m+P-1}\Big{\|}\Big{(}\frac{a_n}{a_m}\nabla J(\theta_n)
  -\nabla J(\theta_{m})\Big{)}\Big{\|}\\
  &=\bar{C}\sum_{n=m+1}^{m+P-1}\Bigg{\|}\Big{(}\frac{a_n}{a_m}-1\Big{)}\nabla J(\theta_n)
   +\Big{(}\nabla J(\theta_n)-\nabla J(\theta_{m})\Big{)}\Bigg{\|}\\
  &\leq \bar{C}\sum_{n=m+1}^{m+P-1}\Bigg{\|}\Big{(}\frac{a_n}{a_m}-1\Big{)}\nabla J(\theta_n)\Bigg{\|}
  +\Bigg{\|}\nabla J(\theta_n)-\nabla J(\theta_{m})\Bigg{\|}
 % \\ &\text{The claim now follows from assumptions (A1) and (A2).}\\
 \end{align*}
 The claim now follows from assumptions (A1) and (A2).
 Now observe that $\|J(\theta_{m+k})-J(\theta_{m})\|\rightarrow 0$ as $m\rightarrow \infty,$
 for all $k \in \{1,\cdots,P\}$ as a consequence of (A1)
 and lemma3. Moreover from $d_m=-\sum_{n=m+1}^{m+P-1}d_n$ we have
\begin{align*}
%   &\text{Now observe that $\|J(\theta_{m+k})-J(\theta_{m})\|\rightarrow 0$ as $m\rightarrow \infty,$}\\
%   &\text{for all $k \in \{1,\cdots,P\}$ as a consequence of (A1)}\\
%   &\text{and lemma3. Moreover from $d_m=-\sum_{n=m+1}^{m+P-1}d_n$ we have}\\
  & \Bigg{\|}\sum_{n=m}^{m+P-1}\frac{b_n}{b_m}d_n J(\theta_n)\Bigg{\|}\\
  & =\Bigg{\|}\sum_{n=m+1}^{m+P-1}\frac{b_n}{b_m}d_n J(\theta_n)+d_m J(\theta_{m})\Bigg{\|}\\
  & =\Bigg{\|}\sum_{n=m+1}^{m+P-1}\frac{b_n}{b_m}d_n J(\theta_n)-\sum_{n=m+1}^{m+P-1}d_n J(\theta_{m})\Bigg{\|}\\
  & =\Bigg{\|}\sum_{n=m+1}^{m+P-1}d_n\Big{(}\frac{b_n}{b_m}J(\theta_n)-J(\theta_{m})\Big{)}\Bigg{\|}\\
  & \leq \sum_{n=m+1}^{m+P-1}\|d_n\|\Big{\|}\Big{(}\frac{b_n}{b_m}J(\theta_n)-J(\theta_{m})\Big{)}\Big{\|}\\
  & \leq C \sum_{n=m+1}^{m+P-1}\Big{\|}\Big{(}\frac{b_n}{b_m}J(\theta_n)-J(\theta_{m})\Big{)}\Big{\|}\\
  & = C \sum_{n=m+1}^{m+P-1} \Bigg{\|}\Big{(}\frac{b_n}{b_m}-1\Big{)} J(\theta_n)
  +\Big{(} J(\theta_n)-J(\theta_{m})\Big{)}\Bigg{\|}\\
  &\leq C \sum_{n=m+1}^{m+P-1}\Bigg{\|}\Big{(}\frac{b_n}{b_m}-1\Big{)} J(\theta_n)\Bigg{\|}
  +\Bigg{\|}\Big{(} J(\theta_n)- J(\theta_{m})\Big{)}\Bigg{\|}
% \\  &\text{The claim now follows as a consequence of}\\ 
%  &\text{assumptions (A1) and (A2).}
\end{align*}
The claim now follows as a consequence of assumptions (A1) and (A2).
\end{proof}
\begin{theorem}
 $\theta_n, n\geq0$ obtained from 1RDSA-2C satisfy $\theta_n \rightarrow G$
 almost surely.
\end{theorem}
\begin{proof}
 Note that
 \begin{align*}
  \begin{split}
  & \theta_{n+P} = \theta_n- \\ 
  &\sum_{l=n}^{n+P-1}a_l\Big{(}\frac{J(\theta_l+\delta_l d_l)-J(\theta_l-\delta_l d_l)}{2\delta_l}d_l+M_{l+1}\Big{)}.
 \end{split}
 \end{align*}
It follows that
 \begin{align*}
  \begin{split}
  & \theta_{n+P} = \theta_n- \sum_{l=n}^{n+P-1}a_l\nabla J(\theta_l)\\ 
  & -\sum_{l=n}^{n+P-1}a_l(d_ld_l^T-I)\nabla J(\theta_l)\\
  & -\sum_{l=n}^{n+P-1}a_l \xi^{1}(\delta_l)-\sum_{l=n}^{n+P-1}a_lM_{l+1}\\
  \end{split}
 \end{align*}
Now the third term on the RHS can be written as
$$a_n\sum_{l=n}^{n+P-1}\frac{a_l}{a_n}D_{l}\nabla J(\theta_l)=a_n\xi_{n},$$
where $\xi_{n}=o(1)$ from lemma 4.
Thus, the algorithm is asymptotically analogous to
$$\theta_{n+1}=\theta_n-a_n(\nabla J(\theta_n)+o(\delta)+M_{n+1}).$$
Hence from chapter 2 of \cite{borkar2008stochastic} we have that $\theta_n, n\geq0$ converge to
local minima of the function $J.$
\end{proof}

\begin{theorem}
  $\theta_n, n\geq0$ obtained from 1RDSA-1C satisfy $\theta_n \rightarrow G$
 almost surely.
\end{theorem}
\begin{proof}
Note that
 \begin{align*}
 \theta_{n+P} = \theta_n-\sum_{l=n}^{n+P-1}a_l\Big{(}\frac{J(\theta_l+\delta_l d_l)}{2\delta_l}\Big{)}d_l-\sum_{l=n}^{n+P-1}a_lM_{l+1}.
 \end{align*} 
It follows that
 \begin{align*}
  \begin{split}
  & \theta_{n+P} = \theta_n- \sum_{l=n}^{n+P-1}a_l\nabla J(\theta_l)\\ 
  & -\sum_{l=n}^{n+P-1}a_l\frac{J(\theta_l)}{\delta_l}d_l-\sum_{l=n}^{n+P-1}a_l(d_ld_l^T-I)\nabla J(\theta_l)\\
  & -\sum_{l=n}^{n+P-1}a_lO(\delta_l)
  -\sum_{l=n}^{n+P-1}a_lM_{l+1}
 \end{split}
 \end{align*}
 Now we observe that
 \begin{align*}
 & \sum_{l=n}^{n+P-1}a_l\frac{J(\theta_l)}{\delta_l}d_l= \sum_{l=n}^{n+P-1} b_{l}J(\theta_l)d_l\\
 & = b_n\sum_{l=n}^{n+P-1}\frac{b_l}{b_n}\frac{J(\theta_l)}{\delta_l}d_l=b_n\xi^{1}_{n},
 \end{align*}
 where $\xi^{1}_{n}=o(1)$ by lemma 4. Similarly
 $$\sum_{l=n}^{n+P-1}a_l(d_ld_l^T-I)\nabla J(\theta_l)=a_n\xi^{2}_{n},$$
 with $\xi^{2}_{n}=o(1)$ by lemma 4.
 The rest follows as explained in Theorem 5.
\end{proof}
